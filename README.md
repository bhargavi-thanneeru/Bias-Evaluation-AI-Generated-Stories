# Evaluation of Bias in AI Generated Content

This project is an in-depth exploration into the biases that may be embedded within the stories generated by different Large Language Models (LLMs). The aim is to discern the nature and extent of gender and racial biases that emerge in response to specific prompts provided to these LLMs.

## Project Overview

The study categorizes prompts into two distinct types: Age-Specific Prompts and Stereotypic Prompts. Age-Specific Prompts are framed to elicit content suitable for children between 1 to 18 years old, while Stereotypic Prompts encompass statements intended to investigate the LLMs' reinforcement or counteraction of stereotypical narratives.

A substantial dataset has been collated, featuring 2,500 stories generated using the ChatGPT API and an additional 2,200 stories sourced from the Gemini API. These narratives have been meticulously annotated to provide a database with attributes such as characters, lead character details, genre, category, and boolean indicators for gender and racial biases.

## Data Cleaning

The data cleaning process involved the following steps:

1. Removing rows with missing values.
2. Removing duplicate rows.
3. Converting data types (e.g., 'Number of Female Characters', 'Number of Male Characters', 'Gender Bias Boolean', and 'Racial Bias Boolean').
4. Categorizing and mapping 'Lead Character Type', 'Genre', and 'Category' columns based on predefined lists and keyword-based functions.
5. Verifying the categorization and mapping changes.

## Analysis and Results

The analysis focused on the following aspects:

1. **Character Types**: Examination of the transition in lead character types (animal to human) across different age groups.
2. **Gender Representation**: Quantification of gender distribution among characters and lead characters, visualized using pie charts.
3. **Bias Analysis**: Identification and visualization of the prevalence of gender and racial biases within the dataset.

The results were segmented into three categories:

1. **Complete Dataset**: Overall insights and visualizations for the entire dataset.
2. **Age-Specific Data Analysis**: Focused analysis on age-specific prompts, including gender distribution and bias quantification.
3. **Stereotypic Prompts Analysis**: Examination of the LLMs' responses to stereotypic prompts, with a focus on gender and racial bias instances.

Detailed explanations for specific instances of gender and racial biases were also documented.

## Conclusion

The project provides a comprehensive evaluation of biases in AI-generated content, shedding light on the models' behavior and areas for improvement. The findings highlight the potential for bias mitigation and the need for continued efforts to promote fairness and inclusivity in AI systems.



